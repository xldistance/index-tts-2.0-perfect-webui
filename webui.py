import json
import os
import sys
import threading
import time
from collections import deque
from datetime import datetime
import queue
import uuid

import warnings

warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning)

import pandas as pd

current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)
sys.path.append(os.path.join(current_dir, "indextts"))

import argparse
parser = argparse.ArgumentParser(
    description="IndexTTS WebUI",
    formatter_class=argparse.ArgumentDefaultsHelpFormatter,
)
parser.add_argument("--verbose", action="store_true", default=False, help="Enable verbose mode")
parser.add_argument("--port", type=int, default=7818, help="Port to run the web UI on")
parser.add_argument("--host", type=str, default="127.0.0.1", help="Host to run the web UI on")
parser.add_argument("--model_dir", type=str, default="./checkpoints", help="Model checkpoints directory")
parser.add_argument("--fp16", action="store_true", default=False, help="Use FP16 for inference if available")
parser.add_argument("--use_deepspeed", action="store_true", default=False, help="Use Deepspeed to accelerate if available")
parser.add_argument("--cuda_kernel", action="store_true", default=False, help="Use cuda kernel for inference if available")
parser.add_argument("--gui_seg_tokens", type=int, default=200, help="GUI: Max tokens per generation segment")
cmd_args = parser.parse_args()

if not os.path.exists(cmd_args.model_dir):
    print(f"Model directory {cmd_args.model_dir} does not exist. Please download the model first.")
    sys.exit(1)

for file in [
    "bpe.model",
    "gpt.pth",
    "config.yaml",
    "s2mel.pth",
    "wav2vec2bert_stats.pt"
]:
    file_path = os.path.join(cmd_args.model_dir, file)
    if not os.path.exists(file_path):
        print(f"Required file {file_path} does not exist. Please download it.")
        sys.exit(1)

import gradio as gr
from indextts.infer_v2 import IndexTTS2
from tools.i18n.i18n import I18nAuto

i18n = I18nAuto(language="Auto")
MODE = 'local'
tts = IndexTTS2(model_dir=cmd_args.model_dir,
                cfg_path=os.path.join(cmd_args.model_dir, "config.yaml"),
                use_fp16=cmd_args.fp16,
                use_deepspeed=cmd_args.use_deepspeed,
                use_cuda_kernel=cmd_args.cuda_kernel,
                )

# æ”¯æŒçš„è¯­è¨€åˆ—è¡¨
LANGUAGES = {
    "ä¸­æ–‡": "zh_CN",
    "English": "en_US"
}
EMO_CHOICES = [i18n("ä¸éŸ³è‰²å‚è€ƒéŸ³é¢‘ç›¸åŒ"),
               i18n("ä½¿ç”¨æƒ…æ„Ÿå‚è€ƒéŸ³é¢‘"),
               i18n("ä½¿ç”¨æƒ…æ„Ÿå‘é‡æ§åˆ¶"),
               i18n("ä½¿ç”¨æƒ…æ„Ÿæè¿°æ–‡æœ¬æ§åˆ¶")]

os.makedirs("outputs/tasks", exist_ok=True)
os.makedirs("prompts", exist_ok=True)
os.makedirs("outputs", exist_ok=True)

# æ–°å¢ï¼šä» saved_timbres ç›®å½•åŠ è½½éŸ³è‰²æ–‡ä»¶
SAVED_TIMBRES_DIR = os.path.join(current_dir, "saved_timbres")
os.makedirs(SAVED_TIMBRES_DIR, exist_ok=True)

SUPPORTED_AUDIO_EXTS = (".wav", ".mp3", ".flac", ".m4a", ".ogg")

# ç”Ÿæˆå†å²è®°å½•ç®¡ç†
generation_history = deque(maxlen=3)  # ä¿å­˜æœ€è¿‘3ä¸ªç”Ÿæˆç»“æœ
generation_lock = threading.Lock()

# ========== é˜Ÿåˆ—ç³»ç»Ÿç›¸å…³å˜é‡ ==========
task_queue = queue.Queue()  # ä»»åŠ¡é˜Ÿåˆ—
queue_status = {}  # å­˜å‚¨æ¯ä¸ªä»»åŠ¡çš„çŠ¶æ€
queue_lock = threading.Lock()  # é˜Ÿåˆ—çŠ¶æ€é”
processing_thread = None  # å¤„ç†çº¿ç¨‹
stop_processing = False  # åœæ­¢å¤„ç†æ ‡å¿—
current_task_id = None  # å½“å‰æ­£åœ¨å¤„ç†çš„ä»»åŠ¡ID

# ä»»åŠ¡çŠ¶æ€æšä¸¾
class TaskStatus:
    PENDING = "ç­‰å¾…ä¸­"
    PROCESSING = "ç”Ÿæˆä¸­"
    COMPLETED = "å·²å®Œæˆ"
    FAILED = "å¤±è´¥"
    CANCELLED = "å·²å–æ¶ˆ"

def list_timbres():
    """è¿”å› saved_timbres ç›®å½•ä¸‹çš„éŸ³é¢‘æ–‡ä»¶ç»å¯¹è·¯å¾„åˆ—è¡¨ï¼ˆæŒ‰æ–‡ä»¶åæ’åºï¼‰ã€‚"""
    files = []
    if os.path.isdir(SAVED_TIMBRES_DIR):
        for fn in os.listdir(SAVED_TIMBRES_DIR):
            if fn.lower().endswith(SUPPORTED_AUDIO_EXTS):
                files.append(os.path.join(SAVED_TIMBRES_DIR, fn))
    files.sort(key=lambda p: os.path.basename(p).lower())
    return files

def get_default_timbre():
    """è·å–é»˜è®¤éŸ³è‰²æ–‡ä»¶ï¼Œä¼˜å…ˆè¿”å›'ç”œç¾å¥³å£°1.mp3'"""
    timbres = list_timbres()
    sweet_voice_path = os.path.join(SAVED_TIMBRES_DIR, "ç”œç¾å¥³å£°1.mp3")
    
    # å¦‚æœå­˜åœ¨"ç”œç¾å¥³å£°1.mp3"ï¼Œè¿”å›å®ƒ
    if sweet_voice_path in timbres:
        return sweet_voice_path
    # å¦åˆ™è¿”å›ç¬¬ä¸€ä¸ªå¯ç”¨çš„éŸ³è‰²
    return timbres[0] if timbres else None

# é¢„è®¡ç®—ä¸‹æ‹‰é»˜è®¤é¡¹ï¼ˆä¾› Examples ä½¿ç”¨ï¼‰
timbre_choices_boot = list_timbres()
default_timbre_boot = get_default_timbre()

MAX_LENGTH_TO_USE_SPEED = 70

# è¯»å–ç¤ºä¾‹ï¼Œç”¨ saved_timbres çš„é»˜è®¤éŸ³è‰²æ–‡ä»¶åšç¬¬ä¸€åˆ—è¾“å…¥
with open("examples/cases.jsonl", "r", encoding="utf-8") as f:
    example_cases = []
    for line in f:
        line = line.strip()
        if not line:
            continue
        example = json.loads(line)
        if example.get("emo_audio", None):
            emo_audio_path = os.path.join("examples", example["emo_audio"])
        else:
            emo_audio_path = None
        example_cases.append([
            default_timbre_boot,  # ç”¨ saved_timbres çš„é»˜è®¤æ–‡ä»¶ä½œä¸ºç¤ºä¾‹çš„éŸ³è‰²å‚è€ƒ
            EMO_CHOICES[example.get("emo_mode", 0)],
            example.get("text"),
            emo_audio_path,
            example.get("emo_weight", 1.0),
            example.get("emo_text", ""),
            example.get("emo_vec_1", 0),
            example.get("emo_vec_2", 0),
            example.get("emo_vec_3", 0),
            example.get("emo_vec_4", 0),
            example.get("emo_vec_5", 0),
            example.get("emo_vec_6", 0),
            example.get("emo_vec_7", 0),
            example.get("emo_vec_8", 0)
        ])

def add_to_history(audio_path):
    """æ·»åŠ æ–°ç”Ÿæˆçš„éŸ³é¢‘åˆ°å†å²è®°å½•"""
    with generation_lock:
        generation_history.append({
            'path': audio_path,
            'time': datetime.now()
        })
def continuous_queue_refresh():
    """æŒç»­åˆ·æ–°é˜Ÿåˆ—çŠ¶æ€çš„ç”Ÿæˆå™¨å‡½æ•°"""
    while True:
        time.sleep(2)  # æ¯2ç§’åˆ·æ–°ä¸€æ¬¡
        yield get_queue_status()
def get_history_display():
    """è·å–å†å²è®°å½•çš„æ˜¾ç¤ºæ ¼å¼"""
    with generation_lock:
        if not generation_history:
            return None, None, None
        
        # å€’åºæ’åˆ—ï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        history_list = list(generation_history)
        history_list.reverse()
        
        result = [None, None, None]
        for i, item in enumerate(history_list[:3]):
            if i < 3:
                result[i] = item['path']
        
        return tuple(result)

def refresh_history():
    """åˆ·æ–°å†å²è®°å½•æ˜¾ç¤ºï¼ˆç‹¬ç«‹å‡½æ•°ï¼‰"""
    hist1, hist2, hist3 = get_history_display()
    return (
        gr.update(value=hist1, visible=hist1 is not None),
        gr.update(value=hist2, visible=hist2 is not None),
        gr.update(value=hist3, visible=hist3 is not None)
    )

# ========== é˜Ÿåˆ—å¤„ç†ç›¸å…³å‡½æ•° ==========
def process_queue():
    """åå°å¤„ç†é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡"""
    global current_task_id, stop_processing
    
    while not stop_processing:
        try:
            # è·å–ä»»åŠ¡ï¼ˆè¶…æ—¶1ç§’ï¼‰
            task = task_queue.get(timeout=1)
            
            if task is None:  # åœæ­¢ä¿¡å·
                break
                
            task_id = task['id']
            current_task_id = task_id
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤„ç†ä¸­
            with queue_lock:
                if task_id in queue_status:
                    if queue_status[task_id]['status'] == TaskStatus.CANCELLED:
                        continue  # è·³è¿‡å·²å–æ¶ˆçš„ä»»åŠ¡
                    queue_status[task_id]['status'] = TaskStatus.PROCESSING
                    queue_status[task_id]['start_time'] = datetime.now()
            
            # æ‰§è¡Œç”Ÿæˆä»»åŠ¡
            try:
                output = gen_single_core(task['params'])
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå®Œæˆ
                with queue_lock:
                    if task_id in queue_status:
                        queue_status[task_id]['status'] = TaskStatus.COMPLETED
                        queue_status[task_id]['output'] = output
                        queue_status[task_id]['end_time'] = datetime.now()
                        
                # æ·»åŠ åˆ°å†å²è®°å½•
                if output:
                    add_to_history(output)
                    
            except Exception as e:
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
                with queue_lock:
                    if task_id in queue_status:
                        queue_status[task_id]['status'] = TaskStatus.FAILED
                        queue_status[task_id]['error'] = str(e)
                        queue_status[task_id]['end_time'] = datetime.now()
            
            current_task_id = None
            
        except queue.Empty:
            continue
        except Exception as e:
            print(f"Queue processing error: {e}")
            current_task_id = None

def gen_single_core(params):
    """æ ¸å¿ƒç”Ÿæˆå‡½æ•°ï¼ˆä»åŸgen_singleæå–ï¼‰"""
    emo_control_method = params['emo_control_method']
    prompt = params['prompt']
    text = params['text']
    emo_ref_path = params['emo_ref_path']
    emo_weight = params['emo_weight']
    vec1, vec2, vec3, vec4, vec5, vec6, vec7, vec8 = params['vec']
    emo_text = params['emo_text']
    emo_random = params['emo_random']
    max_text_tokens_per_segment = params['max_text_tokens_per_segment']
    kwargs = params['kwargs']
    
    # ç”Ÿæˆè¾“å‡ºè·¯å¾„
    timestamp = int(time.time() * 1000)
    output_path = os.path.join("outputs", f"spk_{timestamp}.wav")
    
    if type(emo_control_method) is not int:
        emo_control_method = emo_control_method.value
    if emo_control_method == 0:
        emo_ref_path = None
        emo_weight = 1.0
    if emo_control_method == 1:
        emo_weight = emo_weight
    if emo_control_method == 2:
        vec = [vec1, vec2, vec3, vec4, vec5, vec6, vec7, vec8]
        vec_sum = sum([vec1, vec2, vec3, vec4, vec5, vec6, vec7, vec8])
        if vec_sum > 1.5:
            raise ValueError(i18n("æƒ…æ„Ÿå‘é‡ä¹‹å’Œä¸èƒ½è¶…è¿‡1.5ï¼Œè¯·è°ƒæ•´åé‡è¯•ã€‚"))
    else:
        vec = None

    if emo_text == "":
        emo_text = None

    print(f"Emo control mode:{emo_control_method}, vec:{vec}")
    
    output = tts.infer(spk_audio_prompt=prompt, text=text,
                      output_path=output_path,
                      emo_audio_prompt=emo_ref_path, emo_alpha=emo_weight,
                      emo_vector=vec,
                      use_emo_text=(emo_control_method == 3), emo_text=emo_text, use_random=emo_random,
                      verbose=cmd_args.verbose,
                      max_text_tokens_per_segment=int(max_text_tokens_per_segment),
                      **kwargs)
    
    return output

def add_to_queue(emo_control_method, prompt, text,
                 emo_ref_path, emo_weight,
                 vec1, vec2, vec3, vec4, vec5, vec6, vec7, vec8,
                 emo_text, emo_random,
                 max_text_tokens_per_segment,
                 *args):
    """æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ—"""
    global processing_thread, stop_processing
    
    # å‡†å¤‡å‚æ•°
    do_sample, top_p, top_k, temperature, \
        length_penalty, num_beams, repetition_penalty, max_mel_tokens = args
    kwargs = {
        "do_sample": bool(do_sample),
        "top_p": float(top_p),
        "top_k": int(top_k) if int(top_k) > 0 else None,
        "temperature": float(temperature),
        "length_penalty": float(length_penalty),
        "num_beams": num_beams,
        "repetition_penalty": float(repetition_penalty),
        "max_mel_tokens": int(max_mel_tokens),
    }
    
    # åˆ›å»ºä»»åŠ¡
    task_id = str(uuid.uuid4())
    task = {
        'id': task_id,
        'params': {
            'emo_control_method': emo_control_method,
            'prompt': prompt,
            'text': text,
            'emo_ref_path': emo_ref_path,
            'emo_weight': emo_weight,
            'vec': [vec1, vec2, vec3, vec4, vec5, vec6, vec7, vec8],
            'emo_text': emo_text,
            'emo_random': emo_random,
            'max_text_tokens_per_segment': max_text_tokens_per_segment,
            'kwargs': kwargs
        }
    }
    
    # æ·»åŠ åˆ°é˜Ÿåˆ—çŠ¶æ€
    with queue_lock:
        queue_status[task_id] = {
            'status': TaskStatus.PENDING,
            'text': text[:50] + '...' if len(text) > 50 else text,
            'submit_time': datetime.now(),
            'position': task_queue.qsize() + 1
        }
    
    # æ·»åŠ åˆ°é˜Ÿåˆ—
    task_queue.put(task)
    
    # å¯åŠ¨å¤„ç†çº¿ç¨‹ï¼ˆå¦‚æœè¿˜æ²¡å¯åŠ¨ï¼‰
    if processing_thread is None or not processing_thread.is_alive():
        stop_processing = False
        processing_thread = threading.Thread(target=process_queue, daemon=True)
        processing_thread.start()
    
    return get_queue_status()
def get_queue_status():
    """è·å–é˜Ÿåˆ—çŠ¶æ€ä¿¡æ¯ï¼Œå¹¶åŒæ—¶è¿”å›æœ€è¿‘3æ¡ç”Ÿæˆå†å²çš„æ›´æ–°å€¼"""
    with queue_lock:
        # ç»Ÿè®¡å„çŠ¶æ€ä»»åŠ¡æ•°
        pending_count = sum(1 for s in queue_status.values() if s['status'] == TaskStatus.PENDING)
        processing_count = sum(1 for s in queue_status.values() if s['status'] == TaskStatus.PROCESSING)
        completed_count = sum(1 for s in queue_status.values() if s['status'] == TaskStatus.COMPLETED)

        # è·å–é˜Ÿåˆ—ä¿¡æ¯è¡¨æ ¼
        data = []
        sorted_tasks = sorted(queue_status.items(), key=lambda x: x[1]['submit_time'])

        for idx, (task_id, info) in enumerate(sorted_tasks[-10:], 1):  # åªæ˜¾ç¤ºæœ€è¿‘10ä¸ª
            status_emoji = {
                TaskStatus.PENDING: "â³",
                TaskStatus.PROCESSING: "ğŸ”„",
                TaskStatus.COMPLETED: "âœ…",
                TaskStatus.FAILED: "âŒ",
                TaskStatus.CANCELLED: "ğŸš«"
            }.get(info['status'], "")

            data.append([
                idx,
                info['text'],
                f"{status_emoji} {info['status']}",
                info['submit_time'].strftime("%H:%M:%S")
            ])

        # åˆ›å»ºçŠ¶æ€ä¿¡æ¯
        status_text = f"""
            ### é˜Ÿåˆ—çŠ¶æ€
            - ğŸ”„ **æ­£åœ¨å¤„ç†**: {processing_count} ä¸ªä»»åŠ¡
            - â³ **ç­‰å¾…ä¸­**: {pending_count} ä¸ªä»»åŠ¡  
            - âœ… **å·²å®Œæˆ**: {completed_count} ä¸ªä»»åŠ¡
            - ğŸ“Š **é˜Ÿåˆ—æ€»é•¿åº¦**: {task_queue.qsize()} ä¸ªä»»åŠ¡

            **æç¤º**: ä»»åŠ¡å°†æŒ‰æäº¤æ—¶é—´é¡ºåºä¾æ¬¡å¤„ç†
            """

        # è·å–æœ€æ–°å®Œæˆçš„ä»»åŠ¡è¾“å‡ºï¼ˆç”¨äº output_audioï¼‰
        latest_output = None
        for task_id, info in reversed(sorted_tasks):
            if info['status'] == TaskStatus.COMPLETED and 'output' in info:
                latest_output = info['output']
                break

        # è·å–æœ€è¿‘ä¸‰æ¡å†å²ï¼ˆæœ€æ–°åœ¨å‰ï¼‰
        hist1, hist2, hist3 = get_history_display()

        # è¿”å› 6 ä¸ª gr.updateï¼ˆä¾æ¬¡ä¸ç»‘å®š outputs é¡ºåºå¯¹åº”ï¼‰
        queue_update = gr.update(value=status_text)
        table_update = gr.update(value=data)
        latest_output_update = gr.update(value=latest_output, visible=bool(latest_output)) if latest_output else gr.update()
        hist1_update = gr.update(value=hist1, visible=bool(hist1))
        hist2_update = gr.update(value=hist2, visible=bool(hist2))
        hist3_update = gr.update(value=hist3, visible=bool(hist3))

        return (queue_update, table_update, latest_output_update, hist1_update, hist2_update, hist3_update)

def cancel_task(task_id):
    """å–æ¶ˆæŒ‡å®šä»»åŠ¡"""
    with queue_lock:
        if task_id in queue_status and queue_status[task_id]['status'] == TaskStatus.PENDING:
            queue_status[task_id]['status'] = TaskStatus.CANCELLED
            return f"ä»»åŠ¡ {task_id[:8]}... å·²å–æ¶ˆ"
    return "æ— æ³•å–æ¶ˆè¯¥ä»»åŠ¡"

def clear_completed_tasks():
    """æ¸…é™¤å·²å®Œæˆçš„ä»»åŠ¡"""
    with queue_lock:
        to_remove = [tid for tid, info in queue_status.items() 
                    if info['status'] in [TaskStatus.COMPLETED, TaskStatus.FAILED, TaskStatus.CANCELLED]]
        for tid in to_remove:
            del queue_status[tid]
    return get_queue_status()

def on_input_text_change(text, max_text_tokens_per_segment):
    if text and len(text) > 0:
        text_tokens_list = tts.tokenizer.tokenize(text)

        segments = tts.tokenizer.split_segments(text_tokens_list, max_text_tokens_per_segment=int(max_text_tokens_per_segment))
        data = []
        for i, s in enumerate(segments):
            segment_str = ''.join(s)
            tokens_count = len(s)
            data.append([i, segment_str, tokens_count])
        return {
            segments_preview: gr.update(value=data, visible=True, type="array"),
        }
    else:
        df = pd.DataFrame([], columns=[i18n("åºå·"), i18n("åˆ†å¥å†…å®¹"), i18n("Tokenæ•°")])
        return {
            segments_preview: gr.update(value=df),
        }

def on_method_select(emo_control_method):
    if emo_control_method == 1:
        return (gr.update(visible=True),
                gr.update(visible=False),
                gr.update(visible=False),
                gr.update(visible=False)
                )
    elif emo_control_method == 2:
        return (gr.update(visible=False),
                gr.update(visible=True),
                gr.update(visible=True),
                gr.update(visible=False)
                )
    elif emo_control_method == 3:
        return (gr.update(visible=False),
                gr.update(visible=True),
                gr.update(visible=False),
                gr.update(visible=True)
                )
    else:
        return (gr.update(visible=False),
                gr.update(visible=False),
                gr.update(visible=False),
                gr.update(visible=False)
                )

def update_timbre_preview(selected_path):
    """æ ¹æ®ä¸‹æ‹‰é€‰ä¸­çš„è·¯å¾„ï¼Œæ›´æ–°è¯•å¬æ’­æ”¾å™¨"""
    if selected_path and os.path.exists(selected_path):
        return gr.update(value=selected_path, visible=True)
    return gr.update(value=None, visible=False)

def refresh_timbres():
    """åˆ·æ–° saved_timbres åˆ—è¡¨ï¼Œå¹¶åŒæ—¶æ›´æ–°ä¸‹æ‹‰ä¸è¯•å¬"""
    choices = list_timbres()
    value = get_default_timbre()  # ä½¿ç”¨æ–°çš„é»˜è®¤éŸ³è‰²è·å–å‡½æ•°
    dropdown_update = gr.update(choices=choices, value=value)
    preview_update = gr.update(value=value, visible=bool(value))
    return dropdown_update, preview_update

def auto_refresh_queue():
    """è‡ªåŠ¨åˆ·æ–°é˜Ÿåˆ—çŠ¶æ€"""
    return get_queue_status()

with gr.Blocks(title="IndexTTS Demo") as demo:
    mutex = threading.Lock()
    gr.HTML('''
    <h2><center>IndexTTS2: A Breakthrough in Emotionally Expressive and Duration-Controlled Auto-Regressive Zero-Shot Text-to-Speech</h2>
<p align="center">
<a href='https://arxiv.org/abs/2506.21619'><img src='https://img.shields.io/badge/ArXiv-2506.21619-red'></a>
</p>
    ''')
    with gr.Tab(i18n("éŸ³é¢‘ç”Ÿæˆ")):
        # é˜Ÿåˆ—çŠ¶æ€æ˜¾ç¤ºåŒºåŸŸ
        with gr.Row():
            with gr.Column(scale=2):
                queue_status_display = gr.Markdown(value="### é˜Ÿåˆ—çŠ¶æ€\n- ç­‰å¾…åˆå§‹åŒ–...")
            with gr.Column(scale=1):
                refresh_queue_btn = gr.Button("ğŸ”„ åˆ·æ–°é˜Ÿåˆ—çŠ¶æ€", variant="secondary")
                clear_queue_btn = gr.Button("ğŸ—‘ï¸ æ¸…é™¤å·²å®Œæˆä»»åŠ¡", variant="secondary")
        
        # é˜Ÿåˆ—ä»»åŠ¡åˆ—è¡¨
        with gr.Row():
            queue_table = gr.Dataframe(
                headers=[i18n("åºå·"), i18n("æ–‡æœ¬é¢„è§ˆ"), i18n("çŠ¶æ€"), i18n("æäº¤æ—¶é—´")],
                label=i18n("ä»»åŠ¡é˜Ÿåˆ—ï¼ˆæœ€è¿‘10ä¸ªï¼‰"),
                interactive=False
            )
        
        with gr.Row():
            # éŸ³è‰²å‚è€ƒéŸ³é¢‘æ”¹ä¸ºä» saved_timbres é€‰æ‹©
            timbre_choices = list_timbres()
            default_timbre = get_default_timbre()  # ä½¿ç”¨æ–°çš„é»˜è®¤éŸ³è‰²è·å–å‡½æ•°

            with gr.Column():
                prompt_audio = gr.Dropdown(
                    label=i18n("éŸ³è‰²å‚è€ƒéŸ³é¢‘ï¼ˆä» saved_timbres é€‰æ‹©ï¼‰"),
                    key="prompt_audio",
                    choices=timbre_choices,
                    value=default_timbre,
                    interactive=True,
                )
                refresh_timbres_btn = gr.Button(i18n("åˆ·æ–°éŸ³è‰²åˆ—è¡¨"), variant="secondary")

                # éŸ³è‰²è¯•å¬æ’­æ”¾å™¨
                timbre_preview = gr.Audio(
                    label=i18n("éŸ³è‰²è¯•å¬"),
                    value=default_timbre,
                    visible=bool(default_timbre),
                    autoplay=False
                )

            with gr.Column():
                input_text_single = gr.TextArea(label=i18n("æ–‡æœ¬"), key="input_text_single",
                                                placeholder=i18n("è¯·è¾“å…¥ç›®æ ‡æ–‡æœ¬"),
                                                info=f"{i18n('å½“å‰æ¨¡å‹ç‰ˆæœ¬')}{tts.model_version or '1.0'}")
                with gr.Row():
                    gen_button = gr.Button(i18n("â• æ·»åŠ åˆ°é˜Ÿåˆ—"), key="gen_button", interactive=True, variant="primary")
                    queue_info = gr.Textbox(label="", value="ç‚¹å‡»æŒ‰é’®å°†ä»»åŠ¡æ·»åŠ åˆ°ç”Ÿæˆé˜Ÿåˆ—", interactive=False)

        # å½“å‰ç”Ÿæˆç»“æœå’Œå†å²è®°å½•åŒºåŸŸ
        with gr.Row():
            with gr.Column():
                gr.Markdown("### " + i18n("å½“å‰ç”Ÿæˆç»“æœ"))
                output_audio = gr.Audio(label=i18n("æœ€æ–°ç”Ÿæˆ"), visible=True, key="output_audio")
            
            with gr.Column():
                with gr.Row():
                    gr.Markdown("### " + i18n("ç”Ÿæˆå†å²ï¼ˆæœ€è¿‘3ä¸ªï¼‰"))
                    refresh_history_btn = gr.Button(i18n("åˆ·æ–°å†å²"), size="sm", variant="secondary")
                history_audio_1 = gr.Audio(label=i18n("å†å² 1ï¼ˆæœ€æ–°ï¼‰"), visible=False)
                history_audio_2 = gr.Audio(label=i18n("å†å² 2"), visible=False)
                history_audio_3 = gr.Audio(label=i18n("å†å² 3ï¼ˆæœ€æ—§ï¼‰"), visible=False)

        with gr.Accordion(i18n("åŠŸèƒ½è®¾ç½®")):
            # æƒ…æ„Ÿæ§åˆ¶é€‰é¡¹éƒ¨åˆ†
            with gr.Row():
                emo_control_method = gr.Radio(
                    choices=EMO_CHOICES,
                    type="index",
                    value=EMO_CHOICES[0], label=i18n("æƒ…æ„Ÿæ§åˆ¶æ–¹å¼"))

        # æƒ…æ„Ÿå‚è€ƒéŸ³é¢‘éƒ¨åˆ†
        with gr.Group(visible=False) as emotion_reference_group:
            with gr.Row():
                emo_upload = gr.Audio(label=i18n("ä¸Šä¼ æƒ…æ„Ÿå‚è€ƒéŸ³é¢‘"), type="filepath")

            with gr.Row():
                emo_weight = gr.Slider(label=i18n("æƒ…æ„Ÿæƒé‡"), minimum=0.0, maximum=1.6, value=0.8, step=0.01)

        # æƒ…æ„Ÿéšæœºé‡‡æ ·
        with gr.Row():
            emo_random = gr.Checkbox(label=i18n("æƒ…æ„Ÿéšæœºé‡‡æ ·"), value=False, visible=False)

        # æƒ…æ„Ÿå‘é‡æ§åˆ¶éƒ¨åˆ†
        with gr.Group(visible=False) as emotion_vector_group:
            with gr.Row():
                with gr.Column():
                    vec1 = gr.Slider(label=i18n("å–œ"), minimum=0.0, maximum=1.4, value=0.0, step=0.05)
                    vec2 = gr.Slider(label=i18n("æ€’"), minimum=0.0, maximum=1.4, value=0.0, step=0.05)
                    vec3 = gr.Slider(label=i18n("å“€"), minimum=0.0, maximum=1.4, value=0.0, step=0.05)
                    vec4 = gr.Slider(label=i18n("æƒ§"), minimum=0.0, maximum=1.4, value=0.0, step=0.05)
                with gr.Column():
                    vec5 = gr.Slider(label=i18n("åŒæ¶"), minimum=0.0, maximum=1.4, value=0.0, step=0.05)
                    vec6 = gr.Slider(label=i18n("ä½è½"), minimum=0.0, maximum=1.4, value=0.0, step=0.05)
                    vec7 = gr.Slider(label=i18n("æƒŠå–œ"), minimum=0.0, maximum=1.4, value=0.0, step=0.05)
                    vec8 = gr.Slider(label=i18n("å¹³é™"), minimum=0.0, maximum=1.4, value=0.0, step=0.05)

        with gr.Group(visible=False) as emo_text_group:
            with gr.Row():
                emo_text = gr.Textbox(label=i18n("æƒ…æ„Ÿæè¿°æ–‡æœ¬"),
                                      placeholder=i18n("è¯·è¾“å…¥æƒ…ç»ªæè¿°ï¼ˆæˆ–ç•™ç©ºä»¥è‡ªåŠ¨ä½¿ç”¨ç›®æ ‡æ–‡æœ¬ä½œä¸ºæƒ…ç»ªæè¿°ï¼‰"),
                                      value="",
                                      info=i18n("ä¾‹å¦‚ï¼šé«˜å…´ï¼Œæ„¤æ€’ï¼Œæ‚²ä¼¤ç­‰"))

        with gr.Accordion(i18n("é«˜çº§ç”Ÿæˆå‚æ•°è®¾ç½®"), open=False):
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown(f"**{i18n('GPT2 é‡‡æ ·è®¾ç½®')}** _{i18n('å‚æ•°ä¼šå½±å“éŸ³é¢‘å¤šæ ·æ€§å’Œç”Ÿæˆé€Ÿåº¦è¯¦è§')} [Generation strategies](https://huggingface.co/docs/transformers/main/en/generation_strategies)._")
                    with gr.Row():
                        do_sample = gr.Checkbox(label="do_sample", value=True, info=i18n("æ˜¯å¦è¿›è¡Œé‡‡æ ·"))
                        temperature = gr.Slider(label="temperature", minimum=0.1, maximum=2.0, value=0.8, step=0.1)
                    with gr.Row():
                        top_p = gr.Slider(label="top_p", minimum=0.0, maximum=1.0, value=0.8, step=0.01)
                        top_k = gr.Slider(label="top_k", minimum=0, maximum=100, value=30, step=1)
                        num_beams = gr.Slider(label="num_beams", value=3, minimum=1, maximum=10, step=1)
                    with gr.Row():
                        repetition_penalty = gr.Number(label="repetition_penalty", precision=None, value=10.0, minimum=0.1, maximum=20.0, step=0.1)
                        length_penalty = gr.Number(label="length_penalty", precision=None, value=0.0, minimum=-2.0, maximum=2.0, step=0.1)
                    max_mel_tokens = gr.Slider(label="max_mel_tokens", value=1500, minimum=50, maximum=tts.cfg.gpt.max_mel_tokens, step=10, info=i18n("ç”ŸæˆTokenæœ€å¤§æ•°é‡ï¼Œè¿‡å°å¯¼è‡´éŸ³é¢‘è¢«æˆªæ–­"), key="max_mel_tokens")
                with gr.Column(scale=2):
                    gr.Markdown(f'**{i18n("åˆ†å¥è®¾ç½®")}** _{i18n("å‚æ•°ä¼šå½±å“éŸ³é¢‘è´¨é‡å’Œç”Ÿæˆé€Ÿåº¦")}_')
                    with gr.Row():
                        initial_value = max(20, min(tts.cfg.gpt.max_text_tokens, cmd_args.gui_seg_tokens))
                        max_text_tokens_per_segment = gr.Slider(
                            label=i18n("åˆ†å¥æœ€å¤§Tokenæ•°"), value=initial_value, minimum=20, maximum=tts.cfg.gpt.max_text_tokens, step=2, key="max_text_tokens_per_segment",
                            info=i18n("å»ºè®®80~200ä¹‹é—´ï¼Œå€¼è¶Šå¤§ï¼Œåˆ†å¥è¶Šé•¿ï¼›å€¼è¶Šå°ï¼Œåˆ†å¥è¶Šç¢ï¼›è¿‡å°è¿‡å¤§éƒ½å¯èƒ½å¯¼è‡´éŸ³é¢‘è´¨é‡ä¸é«˜"),
                        )
                    with gr.Accordion(i18n("é¢„è§ˆåˆ†å¥ç»“æœ"), open=True) as segments_settings:
                        segments_preview = gr.Dataframe(
                            headers=[i18n("åºå·"), i18n("åˆ†å¥å†…å®¹"), i18n("Tokenæ•°")],
                            key="segments_preview",
                            wrap=True,
                        )
            advanced_params = [
                do_sample, top_p, top_k, temperature,
                length_penalty, num_beams, repetition_penalty, max_mel_tokens,
            ]

        if len(example_cases) > 0:
            gr.Examples(
                examples=example_cases,
                examples_per_page=20,
                inputs=[prompt_audio,
                        emo_control_method,
                        input_text_single,
                        emo_upload,
                        emo_weight,
                        emo_text,
                        vec1, vec2, vec3, vec4, vec5, vec6, vec7, vec8]
            )

        # äº‹ä»¶ç»‘å®š
        emo_control_method.select(on_method_select,
            inputs=[emo_control_method],
            outputs=[emotion_reference_group,
                     emo_random,
                     emotion_vector_group,
                     emo_text_group]
        )

        input_text_single.change(
            on_input_text_change,
            inputs=[input_text_single, max_text_tokens_per_segment],
            outputs=[segments_preview]
        )
        max_text_tokens_per_segment.change(
            on_input_text_change,
            inputs=[input_text_single, max_text_tokens_per_segment],
            outputs=[segments_preview]
        )

        # ä¸‹æ‹‰å˜åŒ– => æ›´æ–°è¯•å¬
        prompt_audio.change(
            update_timbre_preview,
            inputs=[prompt_audio],
            outputs=[timbre_preview]
        )

        # åˆ·æ–°åˆ—è¡¨ => åŒæ—¶æ›´æ–°ä¸‹æ‹‰å’Œè¯•å¬
        refresh_timbres_btn.click(
            refresh_timbres,
            inputs=[],
            outputs=[prompt_audio, timbre_preview]
        )

        # ç”ŸæˆæŒ‰é’® - ç°åœ¨æ·»åŠ åˆ°é˜Ÿåˆ—
        gen_button.click(
            add_to_queue,
            inputs=[emo_control_method, prompt_audio, input_text_single, emo_upload, emo_weight,
                    vec1, vec2, vec3, vec4, vec5, vec6, vec7, vec8,
                    emo_text, emo_random,
                    max_text_tokens_per_segment,
                    *advanced_params,
                    ],
            outputs=[queue_status_display, queue_table, output_audio]
        ).then(
            lambda: gr.update(value="âœ… ä»»åŠ¡å·²æ·»åŠ åˆ°é˜Ÿåˆ—ï¼Œè¯·ç­‰å¾…å¤„ç†..."),
            outputs=[queue_info]
        )
        
        # åˆ·æ–°é˜Ÿåˆ—çŠ¶æ€
        refresh_queue_btn.click(
            get_queue_status,
            inputs=[],
            outputs=[queue_status_display, queue_table, output_audio]
        )
        
        # æ¸…é™¤å·²å®Œæˆä»»åŠ¡
        clear_queue_btn.click(
            clear_completed_tasks,
            inputs=[],
            outputs=[queue_status_display, queue_table, output_audio]
        )
        
        # åˆ·æ–°å†å²æŒ‰é’® - ç‹¬ç«‹æ›´æ–°å†å²æ˜¾ç¤º
        refresh_history_btn.click(
            refresh_history,
            inputs=[],
            outputs=[history_audio_1, history_audio_2, history_audio_3]
        )
        # è®¾ç½®æŒç»­è¿è¡Œçš„é˜Ÿåˆ—çŠ¶æ€åˆ·æ–°
        demo.load(
            continuous_queue_refresh,
            inputs=[],
            outputs=[queue_status_display, queue_table, output_audio],
            show_progress="hidden"  # éšè—è¿›åº¦æ¡ï¼Œé¿å…ç•Œé¢é—ªçƒ
        )

if __name__ == "__main__":
    # å¯ç”¨é˜Ÿåˆ—åŠŸèƒ½ï¼Œæ”¯æŒå¤šä¸ªç”¨æˆ·æ’é˜Ÿç”Ÿæˆ
    demo.queue(
        max_size=50,  # å¢åŠ é˜Ÿåˆ—é•¿åº¦ä»¥æ”¯æŒæ›´å¤šä»»åŠ¡
        default_concurrency_limit=1  # åŒæ—¶å¤„ç†çš„è¯·æ±‚æ•°ï¼ˆè®¾ä¸º1ç¡®ä¿é¡ºåºå¤„ç†ï¼‰
    )
    
    demo.launch(
        server_name=cmd_args.host,
        server_port=cmd_args.port,
        share=False
    )