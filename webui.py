import json
import os
import sys
import threading
import time
from collections import deque
from datetime import datetime
import queue
import uuid
from pathlib import Path
import warnings
import re
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning)

import pandas as pd

current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)
sys.path.append(os.path.join(current_dir, "indextts"))

import argparse
parser = argparse.ArgumentParser(
    description="IndexTTS WebUI",
    formatter_class=argparse.ArgumentDefaultsHelpFormatter,
)
parser.add_argument("--verbose", action="store_true", default=False, help="Enable verbose mode")
parser.add_argument("--port", type=int, default=7818, help="Port to run the web UI on")
parser.add_argument("--host", type=str, default="127.0.0.1", help="Host to run the web UI on")
parser.add_argument("--model_dir", type=str, default="./checkpoints", help="Model checkpoints directory")
parser.add_argument("--fp16", action="store_true", default=False, help="Use FP16 for inference if available")
parser.add_argument("--use_deepspeed", action="store_true", default=False, help="Use Deepspeed to accelerate if available")
parser.add_argument("--cuda_kernel", action="store_true", default=False, help="Use cuda kernel for inference if available")
parser.add_argument("--gui_seg_tokens", type=int, default=200, help="GUI: Max tokens per generation segment")
cmd_args = parser.parse_args()

if not os.path.exists(cmd_args.model_dir):
    print(f"Model directory {cmd_args.model_dir} does not exist. Please download the model first.")
    sys.exit(1)

for file in [
    "bpe.model",
    "gpt.pth",
    "config.yaml",
    "s2mel.pth",
    "wav2vec2bert_stats.pt"
]:
    file_path = os.path.join(cmd_args.model_dir, file)
    if not os.path.exists(file_path):
        print(f"Required file {file_path} does not exist. Please download it.")
        sys.exit(1)

import gradio as gr
from indextts.infer_v2 import IndexTTS2
from tools.i18n.i18n import I18nAuto

i18n = I18nAuto(language="Auto")
MODE = 'local'
tts = IndexTTS2(model_dir=cmd_args.model_dir,
                cfg_path=os.path.join(cmd_args.model_dir, "config.yaml"),
                use_fp16=cmd_args.fp16,
                use_deepspeed=cmd_args.use_deepspeed,
                use_cuda_kernel=cmd_args.cuda_kernel,
                )

# æ”¯æŒçš„è¯­è¨€åˆ—è¡¨
LANGUAGES = {
    "ä¸­æ–‡": "zh_CN",
    "English": "en_US"
}
EMO_CHOICES = [i18n("ä¸éŸ³è‰²å‚è€ƒéŸ³é¢‘ç›¸åŒ"),
               i18n("ä½¿ç”¨æƒ…æ„Ÿå‚è€ƒéŸ³é¢‘"),
               i18n("ä½¿ç”¨æƒ…æ„Ÿå‘é‡æ§åˆ¶"),
               i18n("ä½¿ç”¨æƒ…æ„Ÿæè¿°æ–‡æœ¬æ§åˆ¶")]

os.makedirs("outputs/tasks", exist_ok=True)
os.makedirs("prompts", exist_ok=True)
os.makedirs("outputs", exist_ok=True)

# æ–°å¢ï¼šä» saved_timbres ç›®å½•åŠ è½½éŸ³è‰²æ–‡ä»¶
SAVED_TIMBRES_DIR = os.path.join(current_dir, "saved_timbres")
os.makedirs(SAVED_TIMBRES_DIR, exist_ok=True)

SUPPORTED_AUDIO_EXTS = (".wav", ".mp3", ".flac", ".m4a", ".ogg")

# ç”Ÿæˆå†å²è®°å½•ç®¡ç†
generation_history = deque(maxlen=10)  # å¢åŠ å†å²è®°å½•æ•°é‡
generation_lock = threading.Lock()

# ========== é˜Ÿåˆ—ç³»ç»Ÿç›¸å…³å˜é‡ ==========
task_queue = queue.Queue()
queue_status = {}
queue_lock = threading.Lock()
processing_thread = None
stop_processing = False
current_task_id = None

# ä»»åŠ¡çŠ¶æ€æšä¸¾
class TaskStatus:
    PENDING = "ç­‰å¾…ä¸­"
    PROCESSING = "ç”Ÿæˆä¸­"
    COMPLETED = "å·²å®Œæˆ"
    FAILED = "å¤±è´¥"
    CANCELLED = "å·²å–æ¶ˆ"

def list_timbres():
    """è¿”å› saved_timbres ç›®å½•ä¸‹çš„éŸ³é¢‘æ–‡ä»¶ç»å¯¹è·¯å¾„åˆ—è¡¨ï¼ˆæŒ‰æ–‡ä»¶åæ’åºï¼‰ã€‚"""
    files = []
    if os.path.isdir(SAVED_TIMBRES_DIR):
        for fn in os.listdir(SAVED_TIMBRES_DIR):
            if fn.lower().endswith(SUPPORTED_AUDIO_EXTS):
                files.append(os.path.join(SAVED_TIMBRES_DIR, fn))
    files.sort(key=lambda p: os.path.basename(p).lower())
    return files

def get_default_timbre():
    """è·å–é»˜è®¤éŸ³è‰²æ–‡ä»¶ï¼Œä¼˜å…ˆè¿”å›'ç”œç¾å¥³å£°1.mp3'"""
    timbres = list_timbres()
    sweet_voice_path = os.path.join(SAVED_TIMBRES_DIR, "ç”œç¾å¥³å£°1.mp3")
    
    if sweet_voice_path in timbres:
        return sweet_voice_path
    return timbres[0] if timbres else None

# é¢„è®¡ç®—ä¸‹æ‹‰é»˜è®¤é¡¹
timbre_choices_boot = list_timbres()
default_timbre_boot = get_default_timbre()

MAX_LENGTH_TO_USE_SPEED = 70

# è¯»å–ç¤ºä¾‹
with open("examples/cases.jsonl", "r", encoding="utf-8") as f:
    example_cases = []
    for line in f:
        line = line.strip()
        if not line:
            continue
        example = json.loads(line)
        if example.get("emo_audio", None):
            emo_audio_path = os.path.join("examples", example["emo_audio"])
        else:
            emo_audio_path = None
        example_cases.append([
            default_timbre_boot,
            EMO_CHOICES[example.get("emo_mode", 0)],
            example.get("text"),
            emo_audio_path,
            example.get("emo_weight", 1.0),
            example.get("emo_text", ""),
            example.get("emo_vec_1", 0),
            example.get("emo_vec_2", 0),
            example.get("emo_vec_3", 0),
            example.get("emo_vec_4", 0),
            example.get("emo_vec_5", 0),
            example.get("emo_vec_6", 0),
            example.get("emo_vec_7", 0),
            example.get("emo_vec_8", 0)
        ])

def add_to_history(audio_path):
    """æ·»åŠ æ–°ç”Ÿæˆçš„éŸ³é¢‘åˆ°å†å²è®°å½•"""
    with generation_lock:
        generation_history.append({
            'path': audio_path,
            'time': datetime.now(),
            'text': ''  # å¯ä»¥å­˜å‚¨ç”Ÿæˆçš„æ–‡æœ¬
        })

def continuous_queue_refresh():
    """æŒç»­åˆ·æ–°é˜Ÿåˆ—çŠ¶æ€çš„ç”Ÿæˆå™¨å‡½æ•°"""
    while True:
        time.sleep(2)
        yield get_queue_status()

def get_history_display():
    """è·å–å†å²è®°å½•çš„æ˜¾ç¤ºæ ¼å¼"""
    with generation_lock:
        if not generation_history:
            return [None] * 6
        
        history_list = list(generation_history)
        history_list.reverse()
        
        result = [None] * 6
        for i, item in enumerate(history_list[:6]):
            if i < 6:
                result[i] = item['path']
        
        return result

def refresh_history():
    """åˆ·æ–°å†å²è®°å½•æ˜¾ç¤º"""
    history = get_history_display()
    return [gr.update(value=h, visible=h is not None) for h in history]

# ========== é˜Ÿåˆ—å¤„ç†ç›¸å…³å‡½æ•° ==========
def process_queue():
    """åå°å¤„ç†é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡"""
    global current_task_id, stop_processing
    
    while not stop_processing:
        try:
            task = task_queue.get(timeout=1)
            
            if task is None:
                break
                
            task_id = task['id']
            current_task_id = task_id
            
            with queue_lock:
                if task_id in queue_status:
                    if queue_status[task_id]['status'] == TaskStatus.CANCELLED:
                        continue
                    queue_status[task_id]['status'] = TaskStatus.PROCESSING
                    queue_status[task_id]['start_time'] = datetime.now()
            
            try:
                output = gen_single_core(task['params'])
                
                with queue_lock:
                    if task_id in queue_status:
                        queue_status[task_id]['status'] = TaskStatus.COMPLETED
                        queue_status[task_id]['output'] = output
                        queue_status[task_id]['end_time'] = datetime.now()
                        
                if output:
                    add_to_history(output)
                    
            except Exception as ex:
                print(f"é˜Ÿåˆ—ç”ŸæˆéŸ³é¢‘å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯ï¼š{ex}")
                with queue_lock:
                    if task_id in queue_status:
                        queue_status[task_id]['status'] = TaskStatus.FAILED
                        queue_status[task_id]['error'] = str(ex)
                        queue_status[task_id]['end_time'] = datetime.now()
            
            current_task_id = None
            
        except queue.Empty:
            continue
        except Exception as ex:
            print(f"Queue processing error: {ex}")
            current_task_id = None

def gen_single_core(params):
    """æ ¸å¿ƒç”Ÿæˆå‡½æ•°"""
    emo_control_method = params['emo_control_method']
    prompt = params['prompt']
    text = params['text']
    emo_ref_path = params['emo_ref_path']
    emo_weight = params['emo_weight']
    vec1, vec2, vec3, vec4, vec5, vec6, vec7, vec8 = params['vec']
    emo_text = params['emo_text']
    emo_random = params['emo_random']
    max_text_tokens_per_segment = params['max_text_tokens_per_segment']
    kwargs = params['kwargs']
    
    timestamp = int(time.time() * 1000)
    cleaned_text = re.sub(r'[\n ]', '', text)
    output_path = os.path.join("outputs", f"{Path(prompt).stem}_{cleaned_text[:20]}_{timestamp}.wav")
    
    if type(emo_control_method) is not int:
        emo_control_method = emo_control_method.value
    if emo_control_method == 0:
        emo_ref_path = None
        emo_weight = 1.0
    if emo_control_method == 1:
        emo_weight = emo_weight
    if emo_control_method == 2:
        vec = [vec1, vec2, vec3, vec4, vec5, vec6, vec7, vec8]
        vec_sum = sum([vec1, vec2, vec3, vec4, vec5, vec6, vec7, vec8])
        if vec_sum > 1.5:
            raise ValueError(i18n("æƒ…æ„Ÿå‘é‡ä¹‹å’Œä¸èƒ½è¶…è¿‡1.5ï¼Œè¯·è°ƒæ•´åé‡è¯•ã€‚"))
    else:
        vec = None

    if emo_text == "":
        emo_text = None

    print(f"Emo control mode:{emo_control_method}, vec:{vec}")
    
    output = tts.infer(spk_audio_prompt=prompt, text=text,
                      output_path=output_path,
                      emo_audio_prompt=emo_ref_path, emo_alpha=emo_weight,
                      emo_vector=vec,
                      use_emo_text=(emo_control_method == 3), emo_text=emo_text, use_random=emo_random,
                      verbose=cmd_args.verbose,
                      max_text_tokens_per_segment=int(max_text_tokens_per_segment),
                      **kwargs)
    
    return output

def add_to_queue(emo_control_method, prompt, text,
                 emo_ref_path, emo_weight,
                 vec1, vec2, vec3, vec4, vec5, vec6, vec7, vec8,
                 emo_text, emo_random,
                 max_text_tokens_per_segment,
                 *args):
    """æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ—"""
    global processing_thread, stop_processing
    
    do_sample, top_p, top_k, temperature, \
        length_penalty, num_beams, repetition_penalty, max_mel_tokens = args
    kwargs = {
        "do_sample": bool(do_sample),
        "top_p": float(top_p),
        "top_k": int(top_k) if int(top_k) > 0 else None,
        "temperature": float(temperature),
        "length_penalty": float(length_penalty),
        "num_beams": num_beams,
        "repetition_penalty": float(repetition_penalty),
        "max_mel_tokens": int(max_mel_tokens),
    }
    
    task_id = str(uuid.uuid4())
    task = {
        'id': task_id,
        'params': {
            'emo_control_method': emo_control_method,
            'prompt': prompt,
            'text': text,
            'emo_ref_path': emo_ref_path,
            'emo_weight': emo_weight,
            'vec': [vec1, vec2, vec3, vec4, vec5, vec6, vec7, vec8],
            'emo_text': emo_text,
            'emo_random': emo_random,
            'max_text_tokens_per_segment': max_text_tokens_per_segment,
            'kwargs': kwargs
        }
    }
    
    with queue_lock:
        queue_status[task_id] = {
            'status': TaskStatus.PENDING,
            'text': text[:50] + '...' if len(text) > 50 else text,
            'submit_time': datetime.now(),
            'position': task_queue.qsize() + 1
        }
    
    task_queue.put(task)
    
    if processing_thread is None or not processing_thread.is_alive():
        stop_processing = False
        processing_thread = threading.Thread(target=process_queue, daemon=True)
        processing_thread.start()
    
    return get_queue_status()

def get_queue_status():
    """è·å–é˜Ÿåˆ—çŠ¶æ€ä¿¡æ¯"""
    with queue_lock:
        pending_count = sum(1 for s in queue_status.values() if s['status'] == TaskStatus.PENDING)
        processing_count = sum(1 for s in queue_status.values() if s['status'] == TaskStatus.PROCESSING)
        completed_count = sum(1 for s in queue_status.values() if s['status'] == TaskStatus.COMPLETED)

        data = []
        sorted_tasks = sorted(queue_status.items(), key=lambda x: x[1]['submit_time'])

        for idx, (task_id, info) in enumerate(sorted_tasks[-10:], 1):
            status_emoji = {
                TaskStatus.PENDING: "â³",
                TaskStatus.PROCESSING: "ğŸ”„",
                TaskStatus.COMPLETED: "âœ…",
                TaskStatus.FAILED: "âŒ",
                TaskStatus.CANCELLED: "ğŸš«"
            }.get(info['status'], "")

            data.append([
                idx,
                info['text'],
                f"{status_emoji} {info['status']}",
                info['submit_time'].strftime("%H:%M:%S")
            ])

        status_text = f"""
        <div style='padding: 10px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 10px; color: white;'>
            <h4 style='margin: 0 0 10px 0;'>ğŸ“Š é˜Ÿåˆ—çŠ¶æ€</h4>
            <div style='display: flex; justify-content: space-around;'>
                <div>ğŸ”„ å¤„ç†ä¸­: <b>{processing_count}</b></div>
                <div>â³ ç­‰å¾…ä¸­: <b>{pending_count}</b></div>
                <div>âœ… å·²å®Œæˆ: <b>{completed_count}</b></div>
                <div>ğŸ“ é˜Ÿåˆ—é•¿åº¦: <b>{task_queue.qsize()}</b></div>
            </div>
        </div>
        """

        latest_output = None
        for task_id, info in reversed(sorted_tasks):
            if info['status'] == TaskStatus.COMPLETED and 'output' in info:
                latest_output = info['output']
                break

        hist1, hist2, hist3, hist4, hist5, hist6 = get_history_display()

        queue_update = gr.update(value=status_text)
        table_update = gr.update(value=data)
        latest_output_update = gr.update(value=latest_output, visible=bool(latest_output)) if latest_output else gr.update()
        
        history_updates = []
        for hist in [hist1, hist2, hist3, hist4, hist5, hist6]:
            history_updates.append(gr.update(value=hist, visible=bool(hist)))

        return (queue_update, table_update, latest_output_update, *history_updates)

def clear_completed_tasks():
    """æ¸…é™¤å·²å®Œæˆçš„ä»»åŠ¡"""
    with queue_lock:
        to_remove = [tid for tid, info in queue_status.items() 
                    if info['status'] in [TaskStatus.COMPLETED, TaskStatus.FAILED, TaskStatus.CANCELLED]]
        for tid in to_remove:
            del queue_status[tid]
    return get_queue_status()

def on_input_text_change(text, max_text_tokens_per_segment):
    if text and len(text) > 0:
        text_tokens_list = tts.tokenizer.tokenize(text)
        segments = tts.tokenizer.split_segments(text_tokens_list, max_text_tokens_per_segment=int(max_text_tokens_per_segment))
        data = []
        for i, s in enumerate(segments):
            segment_str = ''.join(s)
            tokens_count = len(s)
            data.append([i, segment_str, tokens_count])
        return gr.update(value=data, visible=True)
    else:
        return gr.update(value=[])

def on_method_select(emo_control_method):
    if emo_control_method == 1:
        return (gr.update(visible=True),
                gr.update(visible=False),
                gr.update(visible=False),
                gr.update(visible=False))
    elif emo_control_method == 2:
        return (gr.update(visible=False),
                gr.update(visible=True),
                gr.update(visible=True),
                gr.update(visible=False))
    elif emo_control_method == 3:
        return (gr.update(visible=False),
                gr.update(visible=True),
                gr.update(visible=False),
                gr.update(visible=True))
    else:
        return (gr.update(visible=False),
                gr.update(visible=False),
                gr.update(visible=False),
                gr.update(visible=False))

def update_timbre_preview(selected_path):
    """æ ¹æ®ä¸‹æ‹‰é€‰ä¸­çš„è·¯å¾„ï¼Œæ›´æ–°è¯•å¬æ’­æ”¾å™¨"""
    if selected_path and os.path.exists(selected_path):
        return gr.update(value=selected_path, visible=True)
    return gr.update(value=None, visible=False)

def refresh_timbres():
    """åˆ·æ–° saved_timbres åˆ—è¡¨"""
    choices = list_timbres()
    value = get_default_timbre()
    dropdown_update = gr.update(choices=choices, value=value)
    preview_update = gr.update(value=value, visible=bool(value))
    return dropdown_update, preview_update

# è‡ªå®šä¹‰CSSæ ·å¼
custom_css = """
    /* æ¸å˜èƒŒæ™¯ */
    .gradio-container {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        background-attachment: fixed;
    }
    
    /* ä¸»å®¹å™¨æ ·å¼ */
    .container {
        max-width: 1400px !important;
    }
    
    /* æ ‡ç­¾é¡µæ ·å¼ */
    .tabs {
        background: rgba(255, 255, 255, 0.95);
        border-radius: 15px;
        padding: 20px;
        box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
    }
    
    /* æŒ‰é’®æ ·å¼ */
    .primary-btn {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
        color: white !important;
        font-weight: bold !important;
        transition: transform 0.2s !important;
    }
    
    .primary-btn:hover {
        transform: scale(1.05) !important;
    }
    
    /* å¡ç‰‡æ ·å¼ */
    .card {
        background: rgba(255, 255, 255, 0.9);
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    
    /* è¡¨æ ¼æ ·å¼ */
    .dataframe {
        border-radius: 10px !important;
        overflow: hidden !important;
    }
    
    /* éŸ³é¢‘ç»„ä»¶æ ·å¼ */
    audio {
        width: 100% !important;
        border-radius: 10px !important;
    }
    
    /* æ»‘å—æ ·å¼ */
    input[type="range"] {
        background: linear-gradient(to right, #667eea 0%, #764ba2 100%) !important;
    }
    
    /* æ ‡é¢˜æ ·å¼ */
    h1, h2, h3 {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
    }
"""

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(title="IndexTTS Demo", theme=gr.themes.Soft(), css=custom_css) as demo:
    mutex = threading.Lock()
    
    # é¡¶éƒ¨å¯¼èˆªæ 
    with gr.Row():
        gr.HTML('''
        <div style="text-align: center; padding: 20px; background: white; border-radius: 15px; margin-bottom: 20px; box-shadow: 0 4px 6px rgba(0,0,0,0.1);">
            <h1 style="margin: 0; font-size: 2.5em;">ğŸ™ï¸ IndexTTS 2.0</h1>
            <p style="color: #666; margin: 10px 0;">Emotionally Expressive Zero-Shot Text-to-Speech System</p>
            <div style="display: flex; justify-content: center; gap: 20px; margin-top: 15px;">
                <a href='https://arxiv.org/abs/2506.21619' target='_blank' style='text-decoration: none;'>
                    <img src='https://img.shields.io/badge/ArXiv-2506.21619-red' style='height: 25px;'>
                </a>
                <a href='#' style='text-decoration: none;'>
                    <img src='https://img.shields.io/badge/Version-2.0-blue' style='height: 25px;'>
                </a>
                <a href='#' style='text-decoration: none;'>
                    <img src='https://img.shields.io/badge/License-MIT-green' style='height: 25px;'>
                </a>
            </div>
        </div>
        ''')
    
    # ä¸»é€‰é¡¹å¡
    with gr.Tabs(elem_classes="tabs"):
        # ğŸµ éŸ³é¢‘ç”Ÿæˆé€‰é¡¹å¡
        with gr.Tab("ğŸµ éŸ³é¢‘ç”Ÿæˆ", elem_id="generation_tab"):
            # å®æ—¶çŠ¶æ€ç›‘æ§é¢æ¿
            with gr.Row():
                with gr.Column(scale=3):
                    queue_status_display = gr.HTML(value="<div style='padding: 10px;'>åˆå§‹åŒ–ä¸­...</div>")
                with gr.Column(scale=1):
                    with gr.Row():
                        refresh_queue_btn = gr.Button("ğŸ”„ åˆ·æ–°", size="sm", elem_classes="primary-btn")
                        clear_queue_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç†", size="sm")
            
            # ä»»åŠ¡é˜Ÿåˆ—è¡¨æ ¼
            queue_table = gr.Dataframe(
                headers=["åºå·", "æ–‡æœ¬é¢„è§ˆ", "çŠ¶æ€", "æäº¤æ—¶é—´"],
                label="ğŸ“‹ ä»»åŠ¡é˜Ÿåˆ—",
                interactive=False,
                elem_classes="card"
            )
            
            # ä¸»è¦è¾“å…¥åŒºåŸŸ
            with gr.Row():
                with gr.Column(scale=1):
                    # éŸ³è‰²é€‰æ‹©å¡ç‰‡
                    with gr.Group(elem_classes="card"):
                        gr.Markdown("### ğŸ¨ éŸ³è‰²é€‰æ‹©")
                        prompt_audio = gr.Dropdown(
                            label="é€‰æ‹©éŸ³è‰²",
                            choices=timbre_choices_boot,
                            value=default_timbre_boot,
                            interactive=True,
                        )
                        refresh_timbres_btn = gr.Button("åˆ·æ–°åˆ—è¡¨", size="sm")
                        timbre_preview = gr.Audio(
                            label="è¯•å¬",
                            value=default_timbre_boot,
                            visible=bool(default_timbre_boot),
                            autoplay=False
                        )
                
                with gr.Column(scale=2):
                    # æ–‡æœ¬è¾“å…¥å¡ç‰‡
                    with gr.Group(elem_classes="card"):
                        gr.Markdown("### âœï¸ è¾“å…¥æ–‡æœ¬")
                        input_text_single = gr.TextArea(
                            placeholder="è¯·è¾“å…¥è¦è½¬æ¢çš„æ–‡æœ¬å†…å®¹...",
                            lines=5,
                            info=f"æ¨¡å‹ç‰ˆæœ¬: {tts.model_version or '1.0'}"
                        )
                        gen_button = gr.Button(
                            "ğŸš€ æ·»åŠ åˆ°ç”Ÿæˆé˜Ÿåˆ—", 
                            variant="primary", 
                            size="lg",
                            elem_classes="primary-btn"
                        )
            
            # ç”Ÿæˆç»“æœå±•ç¤ºåŒº
            with gr.Row():
                with gr.Column():
                    gr.Markdown("### ğŸ§ æœ€æ–°ç”Ÿæˆ")
                    output_audio = gr.Audio(label="å½“å‰ç»“æœ", visible=True)
                
                with gr.Column():
                    with gr.Row():
                        gr.Markdown("### ğŸ“š å†å²è®°å½•")
                        refresh_history_btn = gr.Button("åˆ·æ–°", size="sm")
                    with gr.Row():
                        history_audio_1 = gr.Audio(label="æœ€è¿‘ 1", visible=False)
                        history_audio_2 = gr.Audio(label="æœ€è¿‘ 2", visible=False)
                    with gr.Row():
                        history_audio_3 = gr.Audio(label="æœ€è¿‘ 3", visible=False)
                        history_audio_4 = gr.Audio(label="æœ€è¿‘ 4", visible=False)
                    with gr.Row():
                        history_audio_5 = gr.Audio(label="æœ€è¿‘ 5", visible=False)
                        history_audio_6 = gr.Audio(label="æœ€è¿‘ 6", visible=False)
        
        # âš™ï¸ é«˜çº§è®¾ç½®é€‰é¡¹å¡
        with gr.Tab("âš™ï¸ é«˜çº§è®¾ç½®", elem_id="settings_tab"):
            # æƒ…æ„Ÿæ§åˆ¶è®¾ç½®
            with gr.Group(elem_classes="card"):
                gr.Markdown("### ğŸ­ æƒ…æ„Ÿæ§åˆ¶")
                emo_control_method = gr.Radio(
                    choices=EMO_CHOICES,
                    type="index",
                    value=EMO_CHOICES[0],
                    label="æ§åˆ¶æ–¹å¼"
                )
                
                # æƒ…æ„Ÿå‚è€ƒéŸ³é¢‘
                with gr.Group(visible=False) as emotion_reference_group:
                    emo_upload = gr.Audio(label="ä¸Šä¼ æƒ…æ„Ÿå‚è€ƒéŸ³é¢‘", type="filepath")
                    emo_weight = gr.Slider(label="æƒ…æ„Ÿæƒé‡", minimum=0.0, maximum=1.6, value=0.8, step=0.01)
                
                # æƒ…æ„Ÿéšæœºé‡‡æ ·
                emo_random = gr.Checkbox(label="å¯ç”¨æƒ…æ„Ÿéšæœºé‡‡æ ·", value=False, visible=False)
                
                # æƒ…æ„Ÿå‘é‡æ§åˆ¶
                with gr.Group(visible=False) as emotion_vector_group:
                    gr.Markdown("#### æƒ…æ„Ÿå‘é‡è°ƒèŠ‚")
                    with gr.Row():
                        with gr.Column():
                            vec1 = gr.Slider(label="ğŸ˜Š å–œ", minimum=0.0, maximum=1.4, value=0.0, step=0.05)
                            vec2 = gr.Slider(label="ğŸ˜  æ€’", minimum=0.0, maximum=1.4, value=0.0, step=0.05)
                            vec3 = gr.Slider(label="ğŸ˜¢ å“€", minimum=0.0, maximum=1.4, value=0.0, step=0.05)
                            vec4 = gr.Slider(label="ğŸ˜¨ æƒ§", minimum=0.0, maximum=1.4, value=0.0, step=0.05)
                        with gr.Column():
                            vec5 = gr.Slider(label="ğŸ¤¢ åŒæ¶", minimum=0.0, maximum=1.4, value=0.0, step=0.05)
                            vec6 = gr.Slider(label="ğŸ˜” ä½è½", minimum=0.0, maximum=1.4, value=0.0, step=0.05)
                            vec7 = gr.Slider(label="ğŸ˜² æƒŠå–œ", minimum=0.0, maximum=1.4, value=0.0, step=0.05)
                            vec8 = gr.Slider(label="ğŸ˜Œ å¹³é™", minimum=0.0, maximum=1.4, value=0.0, step=0.05)
                
                # æƒ…æ„Ÿæ–‡æœ¬æè¿°
                with gr.Group(visible=False) as emo_text_group:
                    emo_text = gr.Textbox(
                        label="æƒ…æ„Ÿæè¿°",
                        placeholder="è¾“å…¥æƒ…ç»ªæè¿°ï¼ˆå¦‚ï¼šé«˜å…´ã€æ„¤æ€’ã€æ‚²ä¼¤ç­‰ï¼‰",
                        value=""
                    )
            
            # ç”Ÿæˆå‚æ•°è®¾ç½®
            with gr.Group(elem_classes="card"):
                gr.Markdown("### ğŸ”§ ç”Ÿæˆå‚æ•°")
                with gr.Row():
                    with gr.Column():
                        gr.Markdown("#### GPT2 é‡‡æ ·å‚æ•°")
                        do_sample = gr.Checkbox(label="å¯ç”¨é‡‡æ ·", value=True)
                        temperature = gr.Slider(label="Temperature", minimum=0.1, maximum=2.0, value=0.8, step=0.1)
                        top_p = gr.Slider(label="Top P", minimum=0.0, maximum=1.0, value=0.8, step=0.01)
                        top_k = gr.Slider(label="Top K", minimum=0, maximum=100, value=30, step=1)
                    
                    with gr.Column():
                        gr.Markdown("#### ç”Ÿæˆæ§åˆ¶")
                        num_beams = gr.Slider(label="Beamæ•°é‡", value=3, minimum=1, maximum=10, step=1)
                        repetition_penalty = gr.Number(label="é‡å¤æƒ©ç½š", value=10.0, minimum=0.1, maximum=20.0)
                        length_penalty = gr.Number(label="é•¿åº¦æƒ©ç½š", value=0.0, minimum=-2.0, maximum=2.0)
                        max_mel_tokens = gr.Slider(label="æœ€å¤§Tokenæ•°", value=1500, minimum=50, maximum=3000, step=10)
            
            # åˆ†å¥è®¾ç½®
            with gr.Group(elem_classes="card"):
                gr.Markdown("### ğŸ“ åˆ†å¥è®¾ç½®")
                max_text_tokens_per_segment = gr.Slider(
                    label="åˆ†å¥æœ€å¤§Tokenæ•°",
                    value=200,
                    minimum=20,
                    maximum=500,
                    step=2,
                    info="å»ºè®®80-200ï¼Œå½±å“éŸ³é¢‘è´¨é‡å’Œç”Ÿæˆé€Ÿåº¦"
                )
                segments_preview = gr.Dataframe(
                    headers=["åºå·", "åˆ†å¥å†…å®¹", "Tokenæ•°"],
                    label="åˆ†å¥é¢„è§ˆ",
                    wrap=True
                )
        
        # ğŸ“– ä½¿ç”¨ç¤ºä¾‹é€‰é¡¹å¡
        with gr.Tab("ğŸ“– ä½¿ç”¨ç¤ºä¾‹", elem_id="examples_tab"):
            if len(example_cases) > 0:
                gr.Examples(
                    examples=example_cases,
                    examples_per_page=10,
                    inputs=[prompt_audio,
                            emo_control_method,
                            input_text_single,
                            emo_upload,
                            emo_weight,
                            emo_text,
                            vec1, vec2, vec3, vec4, vec5, vec6, vec7, vec8],
                    label="ç‚¹å‡»ç¤ºä¾‹å¿«é€Ÿä½“éªŒ"
                )
        
        # â„¹ï¸ å…³äºé€‰é¡¹å¡
        with gr.Tab("â„¹ï¸ å…³äº", elem_id="about_tab"):
            gr.Markdown("""
            ## å…³äº IndexTTS 2.0
            
            IndexTTS æ˜¯ä¸€ä¸ªå…ˆè¿›çš„é›¶æ ·æœ¬æ–‡æœ¬è½¬è¯­éŸ³ç³»ç»Ÿï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š
            
            ### âœ¨ ä¸»è¦ç‰¹æ€§
            - ğŸ­ **æƒ…æ„Ÿè¡¨è¾¾**ï¼šæ”¯æŒå¤šç§æƒ…æ„Ÿæ§åˆ¶æ–¹å¼
            - ğŸ¨ **éŸ³è‰²å…‹éš†**ï¼šä»…éœ€å‡ ç§’å‚è€ƒéŸ³é¢‘å³å¯å…‹éš†éŸ³è‰²
            - âš¡ **é«˜æ•ˆç”Ÿæˆ**ï¼šä¼˜åŒ–çš„æ¨ç†å¼•æ“ï¼Œå¿«é€Ÿç”Ÿæˆé«˜è´¨é‡éŸ³é¢‘
            - ğŸŒ **å¤šè¯­è¨€æ”¯æŒ**ï¼šæ”¯æŒä¸­æ–‡å’Œè‹±æ–‡
            
            ### ğŸ“š ä½¿ç”¨æŒ‡å—
            1. **é€‰æ‹©éŸ³è‰²**ï¼šä»é¢„è®¾éŸ³è‰²ä¸­é€‰æ‹©æˆ–ä¸Šä¼ è‡ªå®šä¹‰éŸ³é¢‘
            2. **è¾“å…¥æ–‡æœ¬**ï¼šè¾“å…¥è¦è½¬æ¢çš„æ–‡æœ¬å†…å®¹
            3. **è°ƒæ•´å‚æ•°**ï¼šæ ¹æ®éœ€è¦è°ƒæ•´æƒ…æ„Ÿå’Œç”Ÿæˆå‚æ•°
            4. **ç”ŸæˆéŸ³é¢‘**ï¼šç‚¹å‡»ç”ŸæˆæŒ‰é’®ï¼Œç­‰å¾…å¤„ç†å®Œæˆ
            
            ### ğŸ”— ç›¸å…³é“¾æ¥
            - [è®ºæ–‡åœ°å€](https://arxiv.org/abs/2506.21619)
            - [GitHubä»“åº“](#)
            - [æ¨¡å‹ä¸‹è½½](#)
            
            ### ğŸ“§ è”ç³»æˆ‘ä»¬
            å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š
            - Email: example@email.com
            - Issue: GitHub Issues
            
            ---
            *Â© 2024 IndexTTS Team. All rights reserved.*
            """)
    
    # é«˜çº§å‚æ•°åˆ—è¡¨ï¼ˆç”¨äºä¼ é€’ï¼‰
    advanced_params = [
        do_sample, top_p, top_k, temperature,
        length_penalty, num_beams, repetition_penalty, max_mel_tokens,
    ]
    
    # äº‹ä»¶ç»‘å®š
    emo_control_method.select(
        on_method_select,
        inputs=[emo_control_method],
        outputs=[emotion_reference_group, emo_random, emotion_vector_group, emo_text_group]
    )
    
    input_text_single.change(
        on_input_text_change,
        inputs=[input_text_single, max_text_tokens_per_segment],
        outputs=[segments_preview]
    )
    
    max_text_tokens_per_segment.change(
        on_input_text_change,
        inputs=[input_text_single, max_text_tokens_per_segment],
        outputs=[segments_preview]
    )
    
    prompt_audio.change(
        update_timbre_preview,
        inputs=[prompt_audio],
        outputs=[timbre_preview]
    )
    
    refresh_timbres_btn.click(
        refresh_timbres,
        inputs=[],
        outputs=[prompt_audio, timbre_preview]
    )
    
    gen_button.click(
        add_to_queue,
        inputs=[emo_control_method, prompt_audio, input_text_single, emo_upload, emo_weight,
                vec1, vec2, vec3, vec4, vec5, vec6, vec7, vec8,
                emo_text, emo_random,
                max_text_tokens_per_segment,
                *advanced_params],
        outputs=[queue_status_display, queue_table, output_audio, 
                 history_audio_1, history_audio_2, history_audio_3,
                 history_audio_4, history_audio_5, history_audio_6]
    )
    
    refresh_queue_btn.click(
        get_queue_status,
        inputs=[],
        outputs=[queue_status_display, queue_table, output_audio,
                 history_audio_1, history_audio_2, history_audio_3,
                 history_audio_4, history_audio_5, history_audio_6]
    )
    
    clear_queue_btn.click(
        clear_completed_tasks,
        inputs=[],
        outputs=[queue_status_display, queue_table, output_audio,
                 history_audio_1, history_audio_2, history_audio_3,
                 history_audio_4, history_audio_5, history_audio_6]
    )
    
    refresh_history_btn.click(
        refresh_history,
        inputs=[],
        outputs=[history_audio_1, history_audio_2, history_audio_3,
                 history_audio_4, history_audio_5, history_audio_6]
    )
    
    # è‡ªåŠ¨åˆ·æ–°é˜Ÿåˆ—çŠ¶æ€
    demo.load(
        continuous_queue_refresh,
        inputs=[],
        outputs=[queue_status_display, queue_table, output_audio,
                 history_audio_1, history_audio_2, history_audio_3,
                 history_audio_4, history_audio_5, history_audio_6],
        show_progress="hidden"
    )

if __name__ == "__main__":
    # å¯ç”¨é˜Ÿåˆ—åŠŸèƒ½
    demo.queue(
        max_size=50,
        default_concurrency_limit=1
    )
    
    demo.launch(
        server_name=cmd_args.host,
        server_port=cmd_args.port,
        share=False,
        favicon_path=None,  # å¯ä»¥æ·»åŠ è‡ªå®šä¹‰å›¾æ ‡
        show_error=True
    )
